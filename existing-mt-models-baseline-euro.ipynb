{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd3edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import tqdm\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from openai import OpenAI\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "\n",
    "import threading\n",
    "import atexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3a8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"exp-data/en-es.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068f84eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction and preliminaries\\nThe focus of t...</td>\n",
       "      <td>Descomposiciones del gráfico de certificación ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction \\nThe popularly accepted theory f...</td>\n",
       "      <td>La evolución del sistema Tierra-Luna basado en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction The chief purpose of this paper i...</td>\n",
       "      <td>Un determinante de los números de ciclo de Sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...</td>\n",
       "      <td>DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Li...</td>\n",
       "      <td>La mecánica cuántica de polímeros y su límite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205959</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>Something is still not right.</td>\n",
       "      <td>Algo aún no está bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205960</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>test</td>\n",
       "      <td>I lost the game.</td>\n",
       "      <td>Perdí el juego.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205961</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I'm really anxious to know what my parents are...</td>\n",
       "      <td>Estoy muy ansioso por saber lo que me van a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205962</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I'll come by later.</td>\n",
       "      <td>Pasaré más tarde.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205963</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>test</td>\n",
       "      <td>Most of the students here go to school on bike.</td>\n",
       "      <td>La mayoría de los alumnos de aquí va a la escu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  split  \\\n",
       "0          scientific_papers_en_es   test   \n",
       "1          scientific_papers_en_es   test   \n",
       "2          scientific_papers_en_es   test   \n",
       "3          scientific_papers_en_es   test   \n",
       "4          scientific_papers_en_es   test   \n",
       "...                            ...    ...   \n",
       "205959  english-spanish-translator  train   \n",
       "205960  english-spanish-translator   test   \n",
       "205961  english-spanish-translator  train   \n",
       "205962  english-spanish-translator  train   \n",
       "205963  english-spanish-translator   test   \n",
       "\n",
       "                                                       EN  \\\n",
       "0       Introduction and preliminaries\\nThe focus of t...   \n",
       "1       Introduction \\nThe popularly accepted theory f...   \n",
       "2       Introduction The chief purpose of this paper i...   \n",
       "3       FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...   \n",
       "4       Polymer Quantum Mechanics and its Continuum Li...   \n",
       "...                                                   ...   \n",
       "205959                      Something is still not right.   \n",
       "205960                                   I lost the game.   \n",
       "205961  I'm really anxious to know what my parents are...   \n",
       "205962                                I'll come by later.   \n",
       "205963    Most of the students here go to school on bike.   \n",
       "\n",
       "                                                       ES  \n",
       "0       Descomposiciones del gráfico de certificación ...  \n",
       "1       La evolución del sistema Tierra-Luna basado en...  \n",
       "2       Un determinante de los números de ciclo de Sti...  \n",
       "3       DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...  \n",
       "4       La mecánica cuántica de polímeros y su límite ...  \n",
       "...                                                   ...  \n",
       "205959                             Algo aún no está bien.  \n",
       "205960                                    Perdí el juego.  \n",
       "205961  Estoy muy ansioso por saber lo que me van a re...  \n",
       "205962                                  Pasaré más tarde.  \n",
       "205963  La mayoría de los alumnos de aquí va a la escu...  \n",
       "\n",
       "[205964 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e8815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3222e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_args = {\n",
    "    \"truncation\": True,\n",
    "    \"padding\": \"longest\",\n",
    "}\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def translate_batch(texts, model, tokenizer, max_text_length=None):\n",
    "    if max_text_length is None:\n",
    "        tok_args = {**tokenizer_args, 'max_length': tokenizer.model_max_length}\n",
    "    else:\n",
    "        tok_args = {**tokenizer_args, 'max_length': max_text_length}\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", **tok_args)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(**inputs)\n",
    "    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098efa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eff2104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scientific_papers_en_es', 'mustc-en-es-text-only', 'corpus-en-es',\n",
       "       'OPUS-books-EN-ES', 'wikipedia_en_es_m2m',\n",
       "       'Document-Translation-en-es', 'medical-translation-test-set',\n",
       "       'english-spanish-translator'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(references, predictions):\n",
    "    assert len(references) == len(predictions), f\"Length mismatch: {len(references)} vs {len(predictions)}\"\n",
    "    references = [[ref] for ref in references]\n",
    "    sacrebleu_score = sacrebleu.compute(predictions=predictions, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=predictions, references=references)[\"score\"]\n",
    "    return {\n",
    "        \"sacrebleu\": sacrebleu_score,\n",
    "        \"chrf\": chrf_score,\n",
    "    }\n",
    "\n",
    "def evaluate(dataset: pd.DataFrame, text_col: str, ref_col: str, translator, save_col=None) -> pd.DataFrame:\n",
    "    translations = []\n",
    "    for i in tqdm.tqdm(range(0, len(dataset), batch_size)):\n",
    "        batch_texts = dataset[text_col].iloc[i:i+batch_size].tolist()\n",
    "        batch_translations = translator(batch_texts)\n",
    "        translations.extend([t.strip() for t in batch_translations])\n",
    "\n",
    "    dataset[save_col] = translations\n",
    "    references = dataset[ref_col].tolist()\n",
    "    \n",
    "    result = {}\n",
    "    datasets_names = dataset['dataset'].unique().tolist()\n",
    "    for name in datasets_names:\n",
    "        sub_dataset = dataset[dataset['dataset'] == name].reset_index(drop=True)\n",
    "        sub_references = sub_dataset[ref_col].tolist()\n",
    "        sub_predictions = sub_dataset[save_col].tolist()\n",
    "        result[name] = get_eval_metrics(sub_references, sub_predictions)\n",
    "    result[\"all\"] = get_eval_metrics(references, translations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ae004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c29958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (13330 > 8192). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus-en-es: 1036 samples\n",
      "scientific_papers_en_es: 180 samples\n",
      "Document-Translation-en-es: 789 samples\n",
      "medical-translation-test-set: 1127 samples\n"
     ]
    }
   ],
   "source": [
    "datasets_names=['corpus-en-es', 'scientific_papers_en_es', 'Document-Translation-en-es', 'medical-translation-test-set']\n",
    "test_df = df[df['dataset'].isin(datasets_names)].reset_index(drop=True)\n",
    "max_per_dataset = 500\n",
    "all_test_df = test_df[test_df['split'] == 'test'].reset_index(drop=True)\n",
    "all_test_df['tokenizer-len'] = all_test_df['EN'].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "# # length less than 1024 tokens\n",
    "all_test_df = all_test_df[all_test_df['tokenizer-len'] < 512].reset_index(drop=True)\n",
    "test_dfs = []\n",
    "for name in datasets_names:\n",
    "    sub_df = all_test_df[all_test_df['dataset'] == name].reset_index(drop=True)\n",
    "    print(f\"{name}: {len(sub_df)} samples\")\n",
    "    if len(sub_df) > max_per_dataset:\n",
    "        sub_df = sub_df.sample(n=max_per_dataset, random_state=42).reset_index(drop=True)\n",
    "    test_dfs.append(sub_df)\n",
    "test_df = pd.concat(test_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9bd4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "      <th>tokenizer-len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>This requires a careful mixture, firstly of ed...</td>\n",
       "      <td>Esta tarea requiere una delicada mezcla, en pr...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>I will therefore merely indicate a few aspects...</td>\n",
       "      <td>Me limito por ello a tocar algunos asuntos tal...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>This is again confirmed in the reports before ...</td>\n",
       "      <td>Esto se confirma de nuevo en los presentes inf...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>This role is not only advisory and observing, ...</td>\n",
       "      <td>No sólo con funciones de asesoramiento y de su...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>In fact there are only two points that I wish ...</td>\n",
       "      <td>De hecho, esta noche sólo quisiera hacer dos c...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>Abstract Primary thyroid lymphomas represent l...</td>\n",
       "      <td>Resumen Los linfomas primarios de tiroides rep...</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>In the 1970s and 1980s, when the developmental...</td>\n",
       "      <td>En las décadas de los 1970 y 1980, cuando el d...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>77.5% of pimecrolimus blood concentrations wer...</td>\n",
       "      <td>El 77,5% de las concentraciones sanguíneas de ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>Administrative interventions associated with i...</td>\n",
       "      <td>Se evaluó un conjunto de iniciativas encaminad...</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>Confidence in cooking skills is relevant in he...</td>\n",
       "      <td>Las competencias culinarias pueden tener relev...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset split  \\\n",
       "0                     corpus-en-es  test   \n",
       "1                     corpus-en-es  test   \n",
       "2                     corpus-en-es  test   \n",
       "3                     corpus-en-es  test   \n",
       "4                     corpus-en-es  test   \n",
       "...                            ...   ...   \n",
       "1675  medical-translation-test-set  test   \n",
       "1676  medical-translation-test-set  test   \n",
       "1677  medical-translation-test-set  test   \n",
       "1678  medical-translation-test-set  test   \n",
       "1679  medical-translation-test-set  test   \n",
       "\n",
       "                                                     EN  \\\n",
       "0     This requires a careful mixture, firstly of ed...   \n",
       "1     I will therefore merely indicate a few aspects...   \n",
       "2     This is again confirmed in the reports before ...   \n",
       "3     This role is not only advisory and observing, ...   \n",
       "4     In fact there are only two points that I wish ...   \n",
       "...                                                 ...   \n",
       "1675  Abstract Primary thyroid lymphomas represent l...   \n",
       "1676  In the 1970s and 1980s, when the developmental...   \n",
       "1677  77.5% of pimecrolimus blood concentrations wer...   \n",
       "1678  Administrative interventions associated with i...   \n",
       "1679  Confidence in cooking skills is relevant in he...   \n",
       "\n",
       "                                                     ES  tokenizer-len  \n",
       "0     Esta tarea requiere una delicada mezcla, en pr...             19  \n",
       "1     Me limito por ello a tocar algunos asuntos tal...             46  \n",
       "2     Esto se confirma de nuevo en los presentes inf...             20  \n",
       "3     No sólo con funciones de asesoramiento y de su...             45  \n",
       "4     De hecho, esta noche sólo quisiera hacer dos c...             30  \n",
       "...                                                 ...            ...  \n",
       "1675  Resumen Los linfomas primarios de tiroides rep...            131  \n",
       "1676  En las décadas de los 1970 y 1980, cuando el d...             59  \n",
       "1677  El 77,5% de las concentraciones sanguíneas de ...             41  \n",
       "1678  Se evaluó un conjunto de iniciativas encaminad...            173  \n",
       "1679  Las competencias culinarias pueden tener relev...             10  \n",
       "\n",
       "[1680 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d24e9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_prompting(text):\n",
    "    return f\"\"\"\n",
    "    Translate the following English text to Spanish.\".\n",
    "    English: {text}\n",
    "    Spanish:\n",
    "    \"\"\"\n",
    "\n",
    "def few_shot_prompting(text):\n",
    "    prompt = (\n",
    "        \"Translate the following English text to Spanish.\\n\\n\"\n",
    "        \"English: Hello, how are you?\\n\"\n",
    "        \"Spanish: Hola, ¿cómo estás? [END]\\n\\n\"\n",
    "        \"English: What is your name?\\n\"\n",
    "        \"Spanish: ¿Cómo te llamas? [END]\\n\\n\"\n",
    "        f\"English: {text}\\n\"\n",
    "        \"Spanish:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def euro_llm_prompting(text):\n",
    "    return f\"English: {text} Spanish:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e72d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n",
      "English: What is your name?\n",
      "Spanish: ¿Cómo te llamas?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize client pointing to your vLLM server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",  # Your server URL\n",
    "    api_key=\"dummy\"  # vLLM doesn't require a real key; use any string\n",
    ")\n",
    "\n",
    "# Plain text prompt\n",
    "prompt = \"Explain quantum computing in simple terms.\"\n",
    "prompt = few_shot_prompting(\"Translate the following English text to Spanish.\")\n",
    "# Generate completion\n",
    "response = client.completions.create(\n",
    "    model=\"utter-project/EuroLLM-1.7B\",  # Must match the served model name\n",
    "    prompt=prompt,\n",
    "    max_tokens=512,                # Shorter output to avoid repetition\n",
    "    temperature=0.0,               # Deterministic output for translation\n",
    "    stop=[\"[END]\"],                # Stop at end-of-translation marker\n",
    "    top_p=1.0,                     # Use full probability mass\n",
    ")\n",
    "\n",
    "# Print the generated text\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd44c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [05:33<00:00,  3.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'corpus-en-es': {'sacrebleu': 38.454873345285336, 'chrf': 63.61917589891719},\n",
       " 'scientific_papers_en_es': {'sacrebleu': 3.9544024305010173e-26,\n",
       "  'chrf': 1.398668872423995},\n",
       " 'Document-Translation-en-es': {'sacrebleu': 47.29710113491373,\n",
       "  'chrf': 70.53279377489669},\n",
       " 'medical-translation-test-set': {'sacrebleu': 46.9690843473075,\n",
       "  'chrf': 71.62701786262872},\n",
       " 'all': {'sacrebleu': 0.00035341397596210975, 'chrf': 9.593348451015476}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"dummy\"\n",
    ")\n",
    "async_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"dummy\"\n",
    ")\n",
    "# ...existing code...\n",
    "\n",
    "async def proc_prompt_async(prompt):\n",
    "    response = await async_client.completions.create(\n",
    "        model=\"utter-project/EuroLLM-1.7B\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        temperature=0.0,\n",
    "        stop=[\"[END]\"],\n",
    "        top_p=1.0,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "async def proc_batch_async(texts, max_concurrency=8, prompt_fn=few_shot_prompting):\n",
    "    prompts = [prompt_fn(t) for t in texts]\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "\n",
    "    async def bounded_call(prompt):\n",
    "        async with semaphore:\n",
    "            return await proc_prompt_async(prompt)\n",
    "\n",
    "    tasks = [bounded_call(p) for p in prompts]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "_bg_loop = asyncio.new_event_loop()\n",
    "_bg_thread = threading.Thread(target=_bg_loop.run_forever, daemon=True)\n",
    "_bg_thread.start()\n",
    "\n",
    "def _shutdown_loop():\n",
    "    _bg_loop.call_soon_threadsafe(_bg_loop.stop)\n",
    "    _bg_thread.join()\n",
    "\n",
    "atexit.register(_shutdown_loop)\n",
    "\n",
    "def proc_batch(texts):\n",
    "    future = asyncio.run_coroutine_threadsafe(proc_batch_async(texts, prompt_fn=euro_llm_prompting), _bg_loop)\n",
    "    return future.result()\n",
    "\n",
    "result = evaluate(test_df, \n",
    "                  text_col='EN', \n",
    "                  ref_col='ES', \n",
    "                  translator=proc_batch, \n",
    "                  save_col='translation')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
