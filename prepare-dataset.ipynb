{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "744597e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "dfs = []\n",
    "max_per_dataset = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c2728b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (1754, 3)\n",
      "after (1754, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"miracFence/scientific_papers_en_es\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "# rename text_no_abstract to EN\n",
    "df = df.rename(columns={\"text_no_abstract\": \"EN\", \"translated\": \"ES\"})\n",
    "df['dataset'] = 'scientific_papers_en_es'\n",
    "df = df[['dataset', 'EN', 'ES']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "df['split'] = 'test'\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11f490b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction and preliminaries\\nThe focus of t...</td>\n",
       "      <td>Descomposiciones del gráfico de certificación ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction \\nThe popularly accepted theory f...</td>\n",
       "      <td>La evolución del sistema Tierra-Luna basado en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction The chief purpose of this paper i...</td>\n",
       "      <td>Un determinante de los números de ciclo de Sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...</td>\n",
       "      <td>DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Li...</td>\n",
       "      <td>La mecánica cuántica de polímeros y su límite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction\\nOur goal in this paper is to emb...</td>\n",
       "      <td>LPTENS–07/16\\nAbril de 2007\\nUna función de on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Microsoft Word - negEntr.doc\\nQuery on Negativ...</td>\n",
       "      <td>Microsoft Word - negEntr.doc\\nConsulta sobre t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction\\n\\tBasis of Two Measures Field Th...</td>\n",
       "      <td>Ausencia del problema de la quinta fuerza en u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Draft version November 16, 2018\\nPreprint type...</td>\n",
       "      <td>Proyecto de versión 16 de noviembre de 2018\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>FERMILAB-PUB-07/076-E\\nSearch for a Higgs boso...</td>\n",
       "      <td>FERMILAB-PUB-07/076-E\\nBúsqueda de un bosón Hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1754 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dataset split  \\\n",
       "0     scientific_papers_en_es  test   \n",
       "1     scientific_papers_en_es  test   \n",
       "2     scientific_papers_en_es  test   \n",
       "3     scientific_papers_en_es  test   \n",
       "4     scientific_papers_en_es  test   \n",
       "...                       ...   ...   \n",
       "1749  scientific_papers_en_es  test   \n",
       "1750  scientific_papers_en_es  test   \n",
       "1751  scientific_papers_en_es  test   \n",
       "1752  scientific_papers_en_es  test   \n",
       "1753  scientific_papers_en_es  test   \n",
       "\n",
       "                                                     EN  \\\n",
       "0     Introduction and preliminaries\\nThe focus of t...   \n",
       "1     Introduction \\nThe popularly accepted theory f...   \n",
       "2     Introduction The chief purpose of this paper i...   \n",
       "3     FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...   \n",
       "4     Polymer Quantum Mechanics and its Continuum Li...   \n",
       "...                                                 ...   \n",
       "1749  Introduction\\nOur goal in this paper is to emb...   \n",
       "1750  Microsoft Word - negEntr.doc\\nQuery on Negativ...   \n",
       "1751  Introduction\\n\\tBasis of Two Measures Field Th...   \n",
       "1752  Draft version November 16, 2018\\nPreprint type...   \n",
       "1753  FERMILAB-PUB-07/076-E\\nSearch for a Higgs boso...   \n",
       "\n",
       "                                                     ES  \n",
       "0     Descomposiciones del gráfico de certificación ...  \n",
       "1     La evolución del sistema Tierra-Luna basado en...  \n",
       "2     Un determinante de los números de ciclo de Sti...  \n",
       "3     DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...  \n",
       "4     La mecánica cuántica de polímeros y su límite ...  \n",
       "...                                                 ...  \n",
       "1749  LPTENS–07/16\\nAbril de 2007\\nUna función de on...  \n",
       "1750  Microsoft Word - negEntr.doc\\nConsulta sobre t...  \n",
       "1751  Ausencia del problema de la quinta fuerza en u...  \n",
       "1752  Proyecto de versión 16 de noviembre de 2018\\nT...  \n",
       "1753  FERMILAB-PUB-07/076-E\\nBúsqueda de un bosón Hi...  \n",
       "\n",
       "[1754 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1065ce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797839cbed3148d3840f355e2d2bd552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f67cc256bf740cda7b7bcecded971a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d366d63d484f08a3f459dedbd5efd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/36.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f165a1b3cea6443fb2c1d85fe23f6dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/320k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d28094aa4224472b1793df039776e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/dev-00000-of-00001.parquet:   0%|          | 0.00/191k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a956488e9f4f1e967ec42da4faadbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/265625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c61e3ff42c4039913c5c7d44efc82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0565c2e822440b8310fa6d0f154061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/1316 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (53818, 4)\n",
      "after (53818, 4)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"kudo-research/mustc-en-es-text-only\")\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "train_df = train_df.sample(n=min(len(train_df), max_per_dataset), random_state=42)\n",
    "val_df = ds[\"dev\"].to_pandas()\n",
    "test_df = ds[\"test\"].to_pandas()\n",
    "train_df['split'] = 'train'\n",
    "val_df['split'] = 'validation'\n",
    "test_df['split'] = 'test'\n",
    "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "df['dataset'] = 'mustc-en-es-text-only'\n",
    "df['EN'] = df['translation'].apply(lambda x: x['en']).str.strip()\n",
    "df['ES'] = df['translation'].apply(lambda x: x['es']).str.strip()\n",
    "df = df[['dataset', 'EN', 'ES', 'split']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ca324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5eb6075c024e46b52a9dad3398bcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/494 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6951b8d4e19f43d395011209e4d1f59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-808c09cb10ce6a(…):   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a3c1c4bf814b6eb90cacfe253b73bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001-f835662a4696f70(…):   0%|          | 0.00/219k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f4437868564ceaa25e5f633b8f4761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3539c10091174853aeb1fa1cd58da0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1049 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (10488, 4)\n",
      "after (10425, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"loresiensis/corpus-en-es\")\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "train_df = train_df.sample(n=min(len(train_df), max_per_dataset), random_state=42)\n",
    "test_df = ds[\"test\"].to_pandas()\n",
    "train_df['split'] = 'train'\n",
    "test_df['split'] = 'test'\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "df['dataset'] = 'corpus-en-es'\n",
    "df = df[['dataset', 'EN', 'ES', 'split']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f6572e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>train</td>\n",
       "      <td>Reading the Laeken resolutions reminded me of ...</td>\n",
       "      <td>Al leer los resultados de Laeken me vino a las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>train</td>\n",
       "      <td>As Mr Herzog said, I do not believe that the a...</td>\n",
       "      <td>A esta visión de renuncia y a la ilusión de un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>train</td>\n",
       "      <td>I therefore agree that we must avoid any kind ...</td>\n",
       "      <td>Reconozco por consiguiente que es necesario ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>train</td>\n",
       "      <td>The ability to impose sanctions is one of the ...</td>\n",
       "      <td>La capacidad de imponer sanciones es uno de lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>train</td>\n",
       "      <td>So which is better - to keep putting away mone...</td>\n",
       "      <td>Así pues, ¿qué es mejor: asignar dinero a defe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>Mr President, Commissioner, the Economic Partn...</td>\n",
       "      <td>Señor Presidente, Señorías, señor Comisario, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10421</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>Rather than rushing to condemn Israel again?</td>\n",
       "      <td>Más que precipitarnos para aplastar de nuevo a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10422</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>The other institutions also need to emulate th...</td>\n",
       "      <td>El sentido de responsabilidad que hoy el Parla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10423</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>Mr President-in-Office, this question raises t...</td>\n",
       "      <td>Señor Presidente en funciones, esta cuestión p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10424</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>The meeting of Foreign Ministers has also exam...</td>\n",
       "      <td>En la reunión de los Ministros de Asuntos Exte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10425 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset  split                                                 EN  \\\n",
       "0      corpus-en-es  train  Reading the Laeken resolutions reminded me of ...   \n",
       "1      corpus-en-es  train  As Mr Herzog said, I do not believe that the a...   \n",
       "2      corpus-en-es  train  I therefore agree that we must avoid any kind ...   \n",
       "3      corpus-en-es  train  The ability to impose sanctions is one of the ...   \n",
       "4      corpus-en-es  train  So which is better - to keep putting away mone...   \n",
       "...             ...    ...                                                ...   \n",
       "10420  corpus-en-es   test  Mr President, Commissioner, the Economic Partn...   \n",
       "10421  corpus-en-es   test       Rather than rushing to condemn Israel again?   \n",
       "10422  corpus-en-es   test  The other institutions also need to emulate th...   \n",
       "10423  corpus-en-es   test  Mr President-in-Office, this question raises t...   \n",
       "10424  corpus-en-es   test  The meeting of Foreign Ministers has also exam...   \n",
       "\n",
       "                                                      ES  \n",
       "0      Al leer los resultados de Laeken me vino a las...  \n",
       "1      A esta visión de renuncia y a la ilusión de un...  \n",
       "2      Reconozco por consiguiente que es necesario ev...  \n",
       "3      La capacidad de imponer sanciones es uno de lo...  \n",
       "4      Así pues, ¿qué es mejor: asignar dinero a defe...  \n",
       "...                                                  ...  \n",
       "10420  Señor Presidente, Señorías, señor Comisario, e...  \n",
       "10421  Más que precipitarnos para aplastar de nuevo a...  \n",
       "10422  El sentido de responsabilidad que hoy el Parla...  \n",
       "10423  Señor Presidente en funciones, esta cuestión p...  \n",
       "10424  En la reunión de los Ministros de Asuntos Exte...  \n",
       "\n",
       "[10425 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac24e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3aba71656b4356971ee6751f889557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef94a640ec61486194e14c5814f380f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "english-to-spanish-translations.parquet:   0%|          | 0.00/14.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae6d8f444124ec79ba003088a46c713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/93470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (50000, 3)\n",
      "after (50000, 4)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"Thermostatic/OPUS-books-EN-ES\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "df = df.sample(n=min(len(df), max_per_dataset), random_state=42)\n",
    "# English to EN and Spanish to ES\n",
    "df = df.rename(columns={\"English\": \"EN\", \"Spanish\": \"ES\"})\n",
    "df['dataset'] = 'OPUS-books-EN-ES'\n",
    "df = df[['dataset', 'EN', 'ES']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "df['split'] = ['train' if random.random() < 0.8 else 'test' for _ in range(len(df))]\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9821b669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>He was the friend of the king, who honored hig...</td>\n",
       "      <td>Era el amigo del rey, que honraba mucho, como ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>Oblonsky was right in this surmise.</td>\n",
       "      <td>Esteban Arkadievich acertaba.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>\"Sixteen minutes to nine!\" said John Sullivan,...</td>\n",
       "      <td>¡Las ocho y cuarenta y cuatro! dijo John Suili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>I stared at him with horror and disgust.</td>\n",
       "      <td>Lo contemplé con un sentimiento de horror.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>The Canadian and I sat him up; we massaged his...</td>\n",
       "      <td>El canadiense y yo le levantamos y le friccion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>\"Were they on the same side of the path as the...</td>\n",
       "      <td>-¿Estaban en el lado del paseo donde se encuen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>\"Evening approaches,\" said I, as I looked towa...</td>\n",
       "      <td>«Ya está oscureciendo -medité, acercándome a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>All, you know, is prepared for prompt departur...</td>\n",
       "      <td>Todo está preparado para tu marcha. Mañana pue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>Who would think that the Evil One had already ...</td>\n",
       "      <td>¿Quién pensaría que el Enemigo tiene en ella u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>OPUS-books-EN-ES</td>\n",
       "      <td>train</td>\n",
       "      <td>But in spite of this, Levin thought matters we...</td>\n",
       "      <td>Pero, a pesar de todo esto, Levin creía que la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset  split  \\\n",
       "0      OPUS-books-EN-ES  train   \n",
       "1      OPUS-books-EN-ES  train   \n",
       "2      OPUS-books-EN-ES  train   \n",
       "3      OPUS-books-EN-ES  train   \n",
       "4      OPUS-books-EN-ES  train   \n",
       "...                 ...    ...   \n",
       "49995  OPUS-books-EN-ES  train   \n",
       "49996  OPUS-books-EN-ES  train   \n",
       "49997  OPUS-books-EN-ES  train   \n",
       "49998  OPUS-books-EN-ES  train   \n",
       "49999  OPUS-books-EN-ES  train   \n",
       "\n",
       "                                                      EN  \\\n",
       "0      He was the friend of the king, who honored hig...   \n",
       "1                    Oblonsky was right in this surmise.   \n",
       "2      \"Sixteen minutes to nine!\" said John Sullivan,...   \n",
       "3               I stared at him with horror and disgust.   \n",
       "4      The Canadian and I sat him up; we massaged his...   \n",
       "...                                                  ...   \n",
       "49995  \"Were they on the same side of the path as the...   \n",
       "49996  \"Evening approaches,\" said I, as I looked towa...   \n",
       "49997  All, you know, is prepared for prompt departur...   \n",
       "49998  Who would think that the Evil One had already ...   \n",
       "49999  But in spite of this, Levin thought matters we...   \n",
       "\n",
       "                                                      ES  \n",
       "0      Era el amigo del rey, que honraba mucho, como ...  \n",
       "1                          Esteban Arkadievich acertaba.  \n",
       "2      ¡Las ocho y cuarenta y cuatro! dijo John Suili...  \n",
       "3             Lo contemplé con un sentimiento de horror.  \n",
       "4      El canadiense y yo le levantamos y le friccion...  \n",
       "...                                                  ...  \n",
       "49995  -¿Estaban en el lado del paseo donde se encuen...  \n",
       "49996  «Ya está oscureciendo -medité, acercándome a l...  \n",
       "49997  Todo está preparado para tu marcha. Mañana pue...  \n",
       "49998  ¿Quién pensaría que el Enemigo tiene en ella u...  \n",
       "49999  Pero, a pesar de todo esto, Levin creía que la...  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c4d59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72896e6bc22427abb8deca8c0b053b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/598 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d255cba2e6e549aeb4101f789aa97106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/29.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a157811fbb945f48d2ca3f37772d451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/5.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab848b1e487945ffa9355ccbf3c39cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22a8d4a83b74f3091b2f165d31915f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (30000, 4)\n",
      "after (30000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"ignacioct/wikipedia_en_es_m2m\")\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "test_df = ds[\"test\"].to_pandas()\n",
    "train_df['split'] = 'train'\n",
    "test_df['split'] = 'test'\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "df['dataset'] = 'wikipedia_en_es_m2m'\n",
    "# en_sentence to EN and es_sentence to ES\n",
    "df = df.rename(columns={\"en_sentence\": \"EN\", \"es_sentence\": \"ES\"})\n",
    "df = df[['dataset', 'EN', 'ES', 'split']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daba3a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f57a180b74a78a08cc269a0de0986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93d5821ecb54f0cad6bc97bc2d97ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/43.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f651a6869cf4a2bb59db3fd4a9b321e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (10533, 3)\n",
      "after (10533, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"Iker/Document-Translation-en-es\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "df['dataset'] = 'Document-Translation-en-es'\n",
    "# es to ES and en to EN\n",
    "df = df.rename(columns={\"en\": \"EN\", \"es\": \"ES\"})\n",
    "df = df[['dataset', 'EN', 'ES']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "# split into train and test by 80% train and 20% test\n",
    "\n",
    "df['split'] = ['train' if random.random() < 0.8 else 'test' for _ in range(len(df))]\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dc0bfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65ba3abacd74fd3bd2a0ef91c25d413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27deb7afe104b6091782d05c639c507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/en_fr-00000-of-00001.parquet:   0%|          | 0.00/327k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f0edb2a2ad4e0ab8a3981879c3c4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/en_pt-00000-of-00001.parquet:   0%|          | 0.00/322k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab408f1d3a84f4aa147b56f09f41130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/en_es-00000-of-00001.parquet:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e904e066cc714877a98c1c1d4d59d796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/en_ro-00000-of-00001.parquet:   0%|          | 0.00/174k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99281bd07719401abcb3f6d3af7175c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/en_de-00000-of-00001.parquet:   0%|          | 0.00/435k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da08ca75a4044acfb810623781ebb243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en_fr split:   0%|          | 0/1049 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b366c13a9ec74429993c2eddeccf6fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en_pt split:   0%|          | 0/1162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f108166f8e94cfb819c9caa6b1288e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en_es split:   0%|          | 0/1127 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471a9dfd354a42aeaa6443389c6ae653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en_ro split:   0%|          | 0/814 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec44970482904d7ca3476ea8f8dfac2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en_de split:   0%|          | 0/1648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (1127, 3)\n",
      "after (1127, 3)\n",
      "after (1127, 4)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"aimped/medical-translation-test-set\")\n",
    "df = ds[\"en_es\"].to_pandas()\n",
    "df['dataset'] = 'medical-translation-test-set'\n",
    "# source to EN and target to ES\n",
    "df = df.rename(columns={\"source\": \"EN\", \"target\": \"ES\"})\n",
    "df = df[['dataset', 'EN', 'ES']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "print(\"after\", df.shape)\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "df['split'] = 'test'\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd44a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53321e6b37fb491dbeb71f5b72c24bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/325 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c139e43e534f86b83d4e995b1f5b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/6.19M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b986e541a3487498d5137246de4c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/118964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (50000, 3)\n",
      "after (50000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"kirchik47/english-spanish-translator\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "df = df.sample(n=min(len(df), max_per_dataset), random_state=42)\n",
    "df['dataset'] = 'english-spanish-translator'\n",
    "# sentences_en to EN and sentences_es to ES\n",
    "df = df.rename(columns={\"sentences_en\": \"EN\", \"sentences_es\": \"ES\"})\n",
    "df = df[['dataset', 'EN', 'ES']]\n",
    "# remove null on ES or EN\n",
    "print(\"before\", df.shape)\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "df['split'] = ['train' if random.random() < 0.8 else 'test' for _ in range(len(df))]\n",
    "print(\"after\", df.shape)\n",
    "df = df[['dataset', 'split', 'EN', 'ES']].reset_index(drop=True)\n",
    "dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1e58a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction and preliminaries\\nThe focus of t...</td>\n",
       "      <td>Descomposiciones del gráfico de certificación ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction \\nThe popularly accepted theory f...</td>\n",
       "      <td>La evolución del sistema Tierra-Luna basado en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction The chief purpose of this paper i...</td>\n",
       "      <td>Un determinante de los números de ciclo de Sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...</td>\n",
       "      <td>DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Li...</td>\n",
       "      <td>La mecánica cuántica de polímeros y su límite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205959</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>Something is still not right.</td>\n",
       "      <td>Algo aún no está bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205960</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>test</td>\n",
       "      <td>I lost the game.</td>\n",
       "      <td>Perdí el juego.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205961</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I'm really anxious to know what my parents are...</td>\n",
       "      <td>Estoy muy ansioso por saber lo que me van a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205962</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I'll come by later.</td>\n",
       "      <td>Pasaré más tarde.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205963</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>test</td>\n",
       "      <td>Most of the students here go to school on bike.</td>\n",
       "      <td>La mayoría de los alumnos de aquí va a la escu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  split  \\\n",
       "0          scientific_papers_en_es   test   \n",
       "1          scientific_papers_en_es   test   \n",
       "2          scientific_papers_en_es   test   \n",
       "3          scientific_papers_en_es   test   \n",
       "4          scientific_papers_en_es   test   \n",
       "...                            ...    ...   \n",
       "205959  english-spanish-translator  train   \n",
       "205960  english-spanish-translator   test   \n",
       "205961  english-spanish-translator  train   \n",
       "205962  english-spanish-translator  train   \n",
       "205963  english-spanish-translator   test   \n",
       "\n",
       "                                                       EN  \\\n",
       "0       Introduction and preliminaries\\nThe focus of t...   \n",
       "1       Introduction \\nThe popularly accepted theory f...   \n",
       "2       Introduction The chief purpose of this paper i...   \n",
       "3       FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...   \n",
       "4       Polymer Quantum Mechanics and its Continuum Li...   \n",
       "...                                                   ...   \n",
       "205959                      Something is still not right.   \n",
       "205960                                   I lost the game.   \n",
       "205961  I'm really anxious to know what my parents are...   \n",
       "205962                                I'll come by later.   \n",
       "205963    Most of the students here go to school on bike.   \n",
       "\n",
       "                                                       ES  \n",
       "0       Descomposiciones del gráfico de certificación ...  \n",
       "1       La evolución del sistema Tierra-Luna basado en...  \n",
       "2       Un determinante de los números de ciclo de Sti...  \n",
       "3       DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...  \n",
       "4       La mecánica cuántica de polímeros y su límite ...  \n",
       "...                                                   ...  \n",
       "205959                             Algo aún no está bien.  \n",
       "205960                                    Perdí el juego.  \n",
       "205961  Estoy muy ansioso por saber lo que me van a re...  \n",
       "205962                                  Pasaré más tarde.  \n",
       "205963  La mayoría de los alumnos de aquí va a la escu...  \n",
       "\n",
       "[205964 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)\n",
    "# remove null\n",
    "df = df.dropna(subset=['EN', 'ES'])\n",
    "# remove duplicates\n",
    "# apply strip to EN and ES\n",
    "df['EN'] = df['EN'].str.strip()\n",
    "df['ES'] = df['ES'].str.strip()\n",
    "# remove empty strings\n",
    "df = df[(df['EN'] != '') & (df['ES'] != '')]\n",
    "df = df.drop_duplicates(subset=['EN', 'ES']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdfdc149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train         171465\n",
       "test           33195\n",
       "validation      1304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b9394d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to exp-data/en-es.parquet\n",
    "import os\n",
    "\n",
    "os.makedirs(\"exp-data\", exist_ok=True)\n",
    "df.to_parquet(\"exp-data/en-es.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['en-length'] = df['EN'].str.split().apply(len)\n",
    "df['es-length'] = df['ES'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['en-length'].plot.hist(bins=100, range=(0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05982be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['es-length'].plot.hist(bins=100, range=(0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cd1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"exp-data/en-es-train-val.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e193ec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document-Translation-en-es</th>\n",
       "      <td>198</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPUS-books-EN-ES</th>\n",
       "      <td>27993</td>\n",
       "      <td>2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corpus-en-es</th>\n",
       "      <td>6582</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english-spanish-translator</th>\n",
       "      <td>28003</td>\n",
       "      <td>2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustc-en-es-text-only</th>\n",
       "      <td>34462</td>\n",
       "      <td>3466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia_en_es_m2m</th>\n",
       "      <td>2762</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split                       train   val\n",
       "dataset                                \n",
       "Document-Translation-en-es    198    16\n",
       "OPUS-books-EN-ES            27993  2701\n",
       "corpus-en-es                 6582   650\n",
       "english-spanish-translator  28003  2892\n",
       "mustc-en-es-text-only       34462  3466\n",
       "wikipedia_en_es_m2m          2762   275"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_counts = (\n",
    "    df.groupby(['dataset', 'split'])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    "      .reindex(columns=['train', 'val'], fill_value=0)\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "split_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9255e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2901561583.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mkudo-research/mustc-en-es-text-only 50k\u001b[39m\n                                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "miracFence/scientific_papers_en_es 1000 OOD\n",
    "aimped/medical-translation-test-set 1000 OOD\n",
    "Document-Translation-en-es 16 In-domain\n",
    "google/wmt24pp 1000 OOD\n",
    "loresiensis/corpus-en-es 650 In-domain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
