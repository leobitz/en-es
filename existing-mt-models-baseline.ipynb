{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd3edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sacrebleu import corpus_bleu\n",
    "import tqdm\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3a8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"exp-data/en-es.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068f84eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction and preliminaries\\nThe focus of t...</td>\n",
       "      <td>Descomposiciones del gráfico de certificación ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction \\nThe popularly accepted theory f...</td>\n",
       "      <td>La evolución del sistema Tierra-Luna basado en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Introduction The chief purpose of this paper i...</td>\n",
       "      <td>Un determinante de los números de ciclo de Sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...</td>\n",
       "      <td>DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scientific_papers_en_es</td>\n",
       "      <td>test</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Li...</td>\n",
       "      <td>La mecánica cuántica de polímeros y su límite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205959</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>Something is still not right.</td>\n",
       "      <td>Algo aún no está bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205960</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I lost the game.</td>\n",
       "      <td>Perdí el juego.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205961</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I'm really anxious to know what my parents are...</td>\n",
       "      <td>Estoy muy ansioso por saber lo que me van a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205962</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>I'll come by later.</td>\n",
       "      <td>Pasaré más tarde.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205963</th>\n",
       "      <td>english-spanish-translator</td>\n",
       "      <td>train</td>\n",
       "      <td>Most of the students here go to school on bike.</td>\n",
       "      <td>La mayoría de los alumnos de aquí va a la escu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  split  \\\n",
       "0          scientific_papers_en_es   test   \n",
       "1          scientific_papers_en_es   test   \n",
       "2          scientific_papers_en_es   test   \n",
       "3          scientific_papers_en_es   test   \n",
       "4          scientific_papers_en_es   test   \n",
       "...                            ...    ...   \n",
       "205959  english-spanish-translator  train   \n",
       "205960  english-spanish-translator  train   \n",
       "205961  english-spanish-translator  train   \n",
       "205962  english-spanish-translator  train   \n",
       "205963  english-spanish-translator  train   \n",
       "\n",
       "                                                       EN  \\\n",
       "0       Introduction and preliminaries\\nThe focus of t...   \n",
       "1       Introduction \\nThe popularly accepted theory f...   \n",
       "2       Introduction The chief purpose of this paper i...   \n",
       "3       FROM DYADIC Λα TO Λα\\nWAEL ABU-SHAMMALA AND AL...   \n",
       "4       Polymer Quantum Mechanics and its Continuum Li...   \n",
       "...                                                   ...   \n",
       "205959                      Something is still not right.   \n",
       "205960                                   I lost the game.   \n",
       "205961  I'm really anxious to know what my parents are...   \n",
       "205962                                I'll come by later.   \n",
       "205963    Most of the students here go to school on bike.   \n",
       "\n",
       "                                                       ES  \n",
       "0       Descomposiciones del gráfico de certificación ...  \n",
       "1       La evolución del sistema Tierra-Luna basado en...  \n",
       "2       Un determinante de los números de ciclo de Sti...  \n",
       "3       DE DÍA A DÍA\\nWAEL ABU-SHAMMALA Y ALBERTO TORC...  \n",
       "4       La mecánica cuántica de polímeros y su límite ...  \n",
       "...                                                   ...  \n",
       "205959                             Algo aún no está bien.  \n",
       "205960                                    Perdí el juego.  \n",
       "205961  Estoy muy ansioso por saber lo que me van a re...  \n",
       "205962                                  Pasaré más tarde.  \n",
       "205963  La mayoría de los alumnos de aquí va a la escu...  \n",
       "\n",
       "[205964 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e8815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3222e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_args = {\n",
    "    \"truncation\": True,\n",
    "    \"padding\": \"longest\",\n",
    "}\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def translate_batch(texts, model, tokenizer, max_text_length=None):\n",
    "    if max_text_length is None:\n",
    "        tok_args = {**tokenizer_args, 'max_length': tokenizer.model_max_length}\n",
    "    else:\n",
    "        tok_args = {**tokenizer_args, 'max_length': max_text_length}\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", **tok_args)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(**inputs)\n",
    "    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098efa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eff2104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scientific_papers_en_es', 'mustc-en-es-text-only', 'corpus-en-es',\n",
       "       'OPUS-books-EN-ES', 'wikipedia_en_es_m2m',\n",
       "       'Document-Translation-en-es', 'medical-translation-test-set',\n",
       "       'english-spanish-translator'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(references, predictions):\n",
    "    assert len(references) == len(predictions), f\"Length mismatch: {len(references)} vs {len(predictions)}\"\n",
    "    references = [[ref] for ref in references]\n",
    "    sacrebleu_score = sacrebleu.compute(predictions=predictions, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=predictions, references=references)[\"score\"]\n",
    "    return {\n",
    "        \"sacrebleu\": sacrebleu_score,\n",
    "        \"chrf\": chrf_score,\n",
    "    }\n",
    "\n",
    "def evaluate(dataset: pd.DataFrame, text_col: str, ref_col: str, translator, save_col=None) -> pd.DataFrame:\n",
    "    translations = []\n",
    "    for i in tqdm.tqdm(range(0, len(dataset), batch_size)):\n",
    "        batch_texts = dataset[text_col].iloc[i:i+batch_size].tolist()\n",
    "        batch_translations = translator(batch_texts)\n",
    "        translations.extend([t.strip() for t in batch_translations])\n",
    "\n",
    "    dataset[save_col] = translations\n",
    "    references = dataset[ref_col].tolist()\n",
    "    \n",
    "    result = {}\n",
    "    datasets_names = dataset['dataset'].unique().tolist()\n",
    "    for name in datasets_names:\n",
    "        sub_dataset = dataset[dataset['dataset'] == name].reset_index(drop=True)\n",
    "        sub_references = sub_dataset[ref_col].tolist()\n",
    "        sub_predictions = sub_dataset[save_col].tolist()\n",
    "        result[name] = get_eval_metrics(sub_references, sub_predictions)\n",
    "    result[\"all\"] = get_eval_metrics(references, translations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ae004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c29958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus-en-es: 1036 samples\n",
      "scientific_papers_en_es: 1754 samples\n",
      "Document-Translation-en-es: 2140 samples\n",
      "medical-translation-test-set: 1127 samples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"google/wmt24pp\", \"en-es_MX\")\n",
    "\n",
    "datasets_names=[\n",
    "                'wmt24', \n",
    "                'corpus-en-es', \n",
    "                'scientific_papers_en_es', \n",
    "                'Document-Translation-en-es', \n",
    "                'medical-translation-test-set'\n",
    "                ]\n",
    "test_df = df[df['dataset'].isin(datasets_names)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "max_per_dataset = 1000\n",
    "all_test_df = test_df[test_df['split'] == 'test'].reset_index(drop=True)\n",
    "all_test_df['tokenizer-len'] = all_test_df['EN'].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "\n",
    "df = df.rename(columns={\"source\": \"EN\", \"target\": \"ES\"})\n",
    "df['dataset'] = 'wmt24'\n",
    "df['tokenizer-len'] = df['EN'].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "wmt_df = df[['dataset', 'EN', 'ES', 'tokenizer-len']]\n",
    "all_test_df = pd.concat([all_test_df, wmt_df]).reset_index(drop=True)\n",
    "\n",
    "# # length less than 1024 tokens\n",
    "all_test_df = all_test_df[all_test_df['tokenizer-len'] < 512].reset_index(drop=True)\n",
    "test_dfs = []\n",
    "for name in datasets_names:\n",
    "    sub_df = all_test_df[all_test_df['dataset'] == name].reset_index(drop=True)\n",
    "    print(f\"{name}: {len(sub_df)} samples\")\n",
    "    if len(sub_df) > max_per_dataset:\n",
    "        sub_df = sub_df.sample(n=max_per_dataset, random_state=42).reset_index(drop=True)\n",
    "    test_dfs.append(sub_df)\n",
    "test_df = pd.concat(test_dfs).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9bd4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>EN</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>This requires a careful mixture, firstly of ed...</td>\n",
       "      <td>Esta tarea requiere una delicada mezcla, en pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>I will therefore merely indicate a few aspects...</td>\n",
       "      <td>Me limito por ello a tocar algunos asuntos tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>This is again confirmed in the reports before ...</td>\n",
       "      <td>Esto se confirma de nuevo en los presentes inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>This role is not only advisory and observing, ...</td>\n",
       "      <td>No sólo con funciones de asesoramiento y de su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus-en-es</td>\n",
       "      <td>test</td>\n",
       "      <td>In fact there are only two points that I wish ...</td>\n",
       "      <td>De hecho, esta noche sólo quisiera hacer dos c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>Abstract Primary thyroid lymphomas represent l...</td>\n",
       "      <td>Resumen Los linfomas primarios de tiroides rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>In the 1970s and 1980s, when the developmental...</td>\n",
       "      <td>En las décadas de los 1970 y 1980, cuando el d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>77.5% of pimecrolimus blood concentrations wer...</td>\n",
       "      <td>El 77,5% de las concentraciones sanguíneas de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>Administrative interventions associated with i...</td>\n",
       "      <td>Se evaluó un conjunto de iniciativas encaminad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>medical-translation-test-set</td>\n",
       "      <td>test</td>\n",
       "      <td>Confidence in cooking skills is relevant in he...</td>\n",
       "      <td>Las competencias culinarias pueden tener relev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset split  \\\n",
       "0                     corpus-en-es  test   \n",
       "1                     corpus-en-es  test   \n",
       "2                     corpus-en-es  test   \n",
       "3                     corpus-en-es  test   \n",
       "4                     corpus-en-es  test   \n",
       "...                            ...   ...   \n",
       "1995  medical-translation-test-set  test   \n",
       "1996  medical-translation-test-set  test   \n",
       "1997  medical-translation-test-set  test   \n",
       "1998  medical-translation-test-set  test   \n",
       "1999  medical-translation-test-set  test   \n",
       "\n",
       "                                                     EN  \\\n",
       "0     This requires a careful mixture, firstly of ed...   \n",
       "1     I will therefore merely indicate a few aspects...   \n",
       "2     This is again confirmed in the reports before ...   \n",
       "3     This role is not only advisory and observing, ...   \n",
       "4     In fact there are only two points that I wish ...   \n",
       "...                                                 ...   \n",
       "1995  Abstract Primary thyroid lymphomas represent l...   \n",
       "1996  In the 1970s and 1980s, when the developmental...   \n",
       "1997  77.5% of pimecrolimus blood concentrations wer...   \n",
       "1998  Administrative interventions associated with i...   \n",
       "1999  Confidence in cooking skills is relevant in he...   \n",
       "\n",
       "                                                     ES  \n",
       "0     Esta tarea requiere una delicada mezcla, en pr...  \n",
       "1     Me limito por ello a tocar algunos asuntos tal...  \n",
       "2     Esto se confirma de nuevo en los presentes inf...  \n",
       "3     No sólo con funciones de asesoramiento y de su...  \n",
       "4     De hecho, esta noche sólo quisiera hacer dos c...  \n",
       "...                                                 ...  \n",
       "1995  Resumen Los linfomas primarios de tiroides rep...  \n",
       "1996  En las décadas de los 1970 y 1980, cuando el d...  \n",
       "1997  El 77,5% de las concentraciones sanguíneas de ...  \n",
       "1998  Se evaluó un conjunto de iniciativas encaminad...  \n",
       "1999  Las competencias culinarias pueden tener relev...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d86e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\", use_safetensors=True).eval().to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20570845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [04:26<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "def temp_pipe(texts):\n",
    "    return translate_batch(texts, model, tokenizer)\n",
    "\n",
    "result = evaluate(test_df, \n",
    "                  text_col='EN', \n",
    "                  ref_col='ES', \n",
    "                  translator=temp_pipe, \n",
    "                  save_col='translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c1eff8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus-en-es': {'sacrebleu': 41.00412441190293, 'chrf': 65.34878844537437},\n",
       " 'scientific_papers_en_es': {'sacrebleu': 9.434383656625893e-35,\n",
       "  'chrf': 1.7145357464745634},\n",
       " 'Document-Translation-en-es': {'sacrebleu': 5.720246915352961,\n",
       "  'chrf': 27.37935028524006},\n",
       " 'medical-translation-test-set': {'sacrebleu': 47.72202120915231,\n",
       "  'chrf': 72.37640191149148},\n",
       " 'all': {'sacrebleu': 2.7203609518748495e-13, 'chrf': 4.032589086505775}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
